# 主要模型参数

## 模型参数

### model_name_or_path: str

- 在 Huggingface.comodels 到预训练模型或模型标识符的路径
- 必须存在

### cache_dir: Optional[str]

- 你想把从huggingface.co下载的预训练模型存储在哪里
- default=None

## 训练数据参数

### max_seq_length: int

- 标记化后的最大总输入序列长度。序列比这长将被截断，更短的序列将被填充.
- default=128

### train_file: Optional[str]

- 包含训练数据的 csv 或 json 文件.
- default=None

### validation_file: Optional[str]

- 包含验证数据的 csv 或 json 文件.
- default=None

### test_file: Optional[str]

- 包含测试数据的 csv 或 json 文件.
- default=None

## 模型训练参数

### output_dir: str

- 写入模型预测和检查点的输出目录.
- 必须存在

### per_device_train_batch_size: int

- 用于训练的每个 GPU/TPU core/CPU 的批次大小.
- default=8

### per_device_eval_batch_size: int

- 用于评估的每个 GPU/TPU core/CPU 的批次大小.
- default=8

### learning_rate: float

- AdamW 的初始学习率.
- default=5e-5

### weight_decay: float

- AdamW 的权重衰减.
- default=0.0

### adam_beta1: float

- AdamW 优化器的 Beta1
- default=0.9

### adam_beta2: float

- AdamW 优化器的 Beta2
- default=0.999

### num_train_epochs: float

- 要执行的训练轮次总数.
- default=3.0

### dataloader_num_workers: int

- 要用于数据加载的子进程数（仅适用于PyTorch）。0表示将在主进程中加载数据.
- default=0

### label_smoothing_factor: float

- 要应用的标签平滑epsilon（零表示没有标签平滑）.
- default=0.0

### save_total_limit: Optional[int]

- 限制检查点的总数.删除output_dir中的旧的检查点。默认值是无限检查点
- default=None

# 全部模型参数

## 模型参数

### model_name_or_path: str

- 在 Huggingface.comodels 到预训练模型或模型标识符的路径
- 必须存在

### config_name: Optional[str]

- 预训练的配置名称或路径（如果与 model_name 不同）
- default=None

### tokenizer_name: Optional[str]

- 如果与 model_name 不同，则预训练的分词器名称或路径
- default=None

### cache_dir: Optional[str]

- 你想把从huggingface.co下载的预训练模型存储在哪里
- default=None

### use_fast_tokenizer: bool

- 是否使用快速分词器之一（由分词器库支持）.
- default=True

### model_revision: str

- 要使用的特定模型版本（可以是分支名称、标签名称或提交ID）.
- default="main"

### use_auth_token: bool

- 将使用运行 `transformers-cli login` 时生成的token（必须将此脚本与私有模型一起使用）
- default=False

## 训练数据参数

### task_name: Optional[str]

- 要训练的任务的名称: " + ", ".join(task_to_keys.keys())
- default='sst2'

### dataset_name: Optional[str]

- 要使用的数据集的名称（通过数据集库）
- default=None

### dataset_config_name: Optional[str]

- 要使用的数据集的配置名称（通过数据集库）.
- default=None

### max_seq_length: int

- 标记化后的最大总输入序列长度。序列比这长将被截断，更短的序列将被填充.
- default=128

### overwrite_cache: bool

- 是否覆盖缓存的预处理数据集.
- default=False

### pad_to_max_length: bool

- 是否将所有样本填充到`max_seq_length`.如果为 False，将在处理到批处理中的最大长度时动态填充样本.
- default=True

### max_train_samples: Optional[int]

- 出于调试目的或更快的训练，如果设置，则将训练示例的数量截断为此值.
- default=None

### max_eval_samples: Optional[int]

- 出于调试目的或更快的训练，如果设置，则将评估示例的数量截断为此值.
- default=None

	- default=None

### max_predict_samples: Optional[int]

- 出于调试目的或更快的训练，如果设置，则将预测示例的数量截断为此值
- default=None

### train_file: Optional[str]

- 包含训练数据的 csv 或 json 文件.
- default=None

### validation_file: Optional[str]

- 包含验证数据的 csv 或 json 文件.
- default=None

### test_file: Optional[str]

- 包含测试数据的 csv 或 json 文件.
- default=None

## 模型训练参数
(参数较多，10个参数值为一组)

### 1组

- output_dir: str

	- 写入模型预测和检查点的输出目录.
	- 必须存在

- overwrite_output_dir: bool

	- 覆盖输出目录的内容.如果 output_dir 指向检查点目录，则使用它继续训练.
	- default=False

- do_train: bool

	- 是否运行训练.
	- default=False

- do_eval: bool

	- 是否在开发集上运行验证.
	- default=False

- do_predict: bool

	- 是否在测试集上运行预测.
	- default=False

- evaluation_strategy: IntervalStrategy(类)

	- 使用的评估策略.
	- default="no"

- prediction_loss_only: bool

	- 执行评估和预测时，只返回损失.
	- default=False

- per_device_train_batch_size: int

	- 用于训练的每个 GPU/TPU core/CPU 的批次大小.
	- default=8

- per_device_eval_batch_size: int

	- 用于评估的每个 GPU/TPU core/CPU 的批次大小.
	- default=8

- per_gpu_train_batch_size: Optional[int]

	- 已弃用，首选使用`--per_device_train_batch_size`. 用于训练的每个 GPU/TPU core/CPU 的批次大小.
	- default=None

		- default=None

### 2组

- per_gpu_eval_batch_size: Optional[int]

	- 已弃用，首选使用`--per_device_eval_batch_size`.用于评估的每个 GPU/TPU core/CPU 的批次大小.
	- default=None

- gradient_accumulation_steps: int

	- 在执行反向传播和参数更新之前要累积的更新步数.
	- default=1

- eval_accumulation_steps: Optional[int]

	- 在将张量移动到 CPU 之前要累积的预测步数.
	- default=None

- learning_rate: float

	- AdamW 的初始学习率.
	- default=5e-5

- weight_decay: float

	- AdamW 的权重衰减.
	- default=0.0

- adam_beta1: float

	- AdamW 优化器的 Beta1
	- default=0.9

- adam_beta2: float

	- AdamW 优化器的 Beta2
	- default=0.999

- adam_epsilon: float

	- 用于 AdamW 优化器的 Epsilon
	- default=1e-8

- max_grad_norm: float

	- 最大梯度范数.
	- default=1.0

- num_train_epochs: float

	- 要执行的训练轮次总数.
	- default=3.0

### 3组

- max_steps: int

	- 如果 > 0：设置要执行的训练步骤总数。覆盖 num_train_epochs.
	- default=-1

- lr_scheduler_type: SchedulerType(类)

	- 要使用的调度程序类型.
	- default="linear"

- warmup_ratio: float

	- 总步数的超过warmup_ratio分数的线性预热.

		- Linear warmup over warmup_ratio fraction of total steps.

	- default=0.0

- warmup_steps: int

	- 通过warmup_steps 进行线性预热.

		- Linear warmup over warmup_steps.

	- default=0

- log_level: Optional[str]

	- 在主节点上使用的记录器日志级别. 可能的选择是日志级别作为字符串: “调试”、“信息”、“警告”、“错误”和“关键”, 加上一个“被动”级别，它不设置任何内容并让应用程序设置级别. 默认为“被动”."
	- default="passive"

- log_level_replica: Optional[str]

	- 在副本节点上使用的记录器日志级别。与“log_level”相同的选择和默认值"
	- default="passive"

- log_on_each_node: bool

	- 在进行多节点分布式训练时，是在每个节点上登录一次或者在主节点上登录一次.
	- default=True

- logging_dir: Optional[str]

	- Tensorboard日志文件.
	- default=None

- logging_strategy: IntervalStrategy(类)

	- 要使用的日志记录策略.
	- default="steps"

- logging_first_step: bool

	- 记录第一个global_step
	- default=False

### 4组

- logging_steps: int

	- 记录每X个更新步骤.
	- default=500

- save_strategy: IntervalStrategy(类)

	- 要使用的检查点保存策略.
	- default="steps"

- save_steps: int

	- 保存每X个更新步骤的检查点.
	- default=500

- save_total_limit: Optional[int]

	- 限制检查点的总数.删除output_dir中的旧的检查点。默认值是无限检查点
	- default=None

- save_on_each_node: bool

	- 在进行多节点分布式训练时，是在每个节点上保存模型和检查点，还是只在主节点上
	- default=False

- no_cuda: bool = field

	- 即使有CUDA可用时，也不要使用它
	- default=False

- seed: int

	- 在训练开始时设置的随机种子.
	- default=42

- fp16: bool

	- 是否使用16位（混合）精度，而不是32位
	- default=False

- fp16_opt_level: str

	- 对于fp16：在[“O0”、“O1”、“O2”和“O3”]中选择的ApexAMP优化级别.详见https://nvidia.github.io/apex/amp.html
	- default="O1"

- fp16_backend: str

	- 用于混合准确率的后端：“自动”、"amp"、“顶端”
	- default="auto"

### 5组

- fp16_full_eval: bool

	- 是否使用完整的16位精度评估，而不是32位
	- default=False

- local_rank: int

	- 分布式训练：local_rank
	- default=-1

- tpu_num_cores: Optional[int]

	- TPU: TPU核心数（由启动器脚本自动传递）
	- default=None

- tpu_metrics_debug: bool

	- 不建议，首选使用`--debug tpu_metrics_debug`。TPU：是否打印调试指标
	- default=False

- debug: str

	- 是否启用调试模式。当前选项:`underflow_overflow` (检测激活物和重量中的过流和溢出),`tpu_metrics_debug` (在TPU上打印调试指标).
	- default=""

- dataloader_drop_last: bool

	- 如果最后一个批不能按批大小整除，则将该不完整批删除.
	- default=False

- eval_steps: int

	- 每X步运行一个评估.
	- default=None

- dataloader_num_workers: int

	- 要用于数据加载的子进程数（仅适用于PyTorch）。0表示将在主进程中加载数据.
	- default=0

- past_index: int

	- 如果>=0，则将输出的相应部分作为下一步的过去状态.
	- default=-1

- run_name: Optional[str]

	- 运行的可选描述符。特别用于wandb logging.
	- default=None

### 6组

- disable_tqdm: Optional[bool]

	- 是否禁用tqdm进度条.
	- default=None

- remove_unused_columns: Optional[bool]

	- 在使用nlp时删除模型不需要的列。数据集.
	- default=True

- label_names: Optional[List[str]]

	- 输入字典中对应于标签的键的列表.
	- default=None

- load_best_model_at_end: Optional[bool]

	- 是否加载训练结束时训练期间找到的最佳模型.
	- default=False

- metric_for_best_model: Optional[str]

	- 用于比较两种不同模型的度量标准.
	- default=None

- greater_is_better: Optional[bool]

	- `最好模型的指标`是否应该被最大化.
	- default=None

- ignore_data_skip: bool

	- 在重新训练时，是否跳过第一个epochs和batches以获得相同的训练数据.
	- default=False

- sharded_ddp: str

	- 是否使用锐度DDP培训（仅在分布式培训中）。基本选项应该是`简单的`，`zero_dp_2`或`zero_dp_3`，您可以将cpu卸载添加到`zero_dp_2`或`zero_dp_3`，就像这样：zero_dp_2卸载`或`zero_dp_3卸载`。您可以添加自动包装到`zero_dp_2`或使用相同的语法：zero_dp_2auto_wrap`或`zero_dp_3auto_wrap`。
	- default=""

- deepspeed: Optional[str]

	- 启用深度速度，并将路径传递给深度json配置文件(例如ds_config.json)或已经加载的json文件
	- default=None

- label_smoothing_factor: float

	- 要应用的标签平滑epsilon（零表示没有标签平滑）.
	- default=0.0

### 7组

- adafactor: bool

	- 是否用Adafactor取代AdamW.
	- default=False

- group_by_length: bool

	- 在批处理时是否将大致相同长度的样本分组在一起.
	- default=False

- length_column_name: Optional[str]

	- 按长度分组时要使用的预先计算长度的列名称.
	- default="length"

- report_to: Optional[List[str]]

	- 报告结果和日志的集成列表.
	- default=None

- ddp_find_unused_parameters: Optional[bool]

	- 当使用分布式训练时，传递给`分布式数据并行`的标志`find_unused_parameters`的值.
	- default=None

- dataloader_pin_memory: bool

	- 是否为数据加载器固定内存.
	- default=True

- skip_memory_metrics: bool

	- 是否跳过添加内存分析器报告到指标.
	- default=True

- use_legacy_prediction_loop: bool

	- 是否在训练中使用遗留的prediction_loop.
	- default=False

- push_to_hub: bool

	- 训练后是否将训练后的模型上传到模型中心.
	- default=False

- resume_from_checkpoint: Optional[str]

	- 到具有模型有效检查点的文件夹的路径.
	- default=None

### 8组

- push_to_hub_model_id: str

	- 将`训练者`推送到其中的存储库的名称.
	- default=None

- push_to_hub_organization: str

	- 其中添加`训练者`进入的组织的名称.
	- default=None

- push_to_hub_token: str

	- 用于推到Model Hub的token.
	- default=None

- _n_gpu: int

	- 参数
	- default=-1

- mp_parameters: str

	- 由SageMaker启动程序用于发送mp-specific的参数。在训练者中被忽视
	- default=""



